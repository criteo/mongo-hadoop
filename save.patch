diff --git a/.gitignore b/.gitignore
index e6dac6f..7a63c22 100644
--- a/.gitignore
+++ b/.gitignore
@@ -39,4 +39,5 @@ testing/*.pyc
 streaming/language_support/python/dist/
 streaming/language_support/python/pymongo_hadoop.egg-info/
 *.splits
-*.crc
\ No newline at end of file
+*.crc
+/bin
diff --git a/core/src/main/java/com/mongodb/hadoop/input/BSONFileRecordReader.java b/core/src/main/java/com/mongodb/hadoop/input/BSONFileRecordReader.java
index 2812e1d..79b7059 100644
--- a/core/src/main/java/com/mongodb/hadoop/input/BSONFileRecordReader.java
+++ b/core/src/main/java/com/mongodb/hadoop/input/BSONFileRecordReader.java
@@ -91,15 +91,12 @@ public class BSONFileRecordReader extends RecordReader<NullWritable, BSONObject>
         codec = compressionCodecs.getCodec(file);
         FileSystem fs = file.getFileSystem(conf);
         FSDataInputStream fileIn = fs.open(file, 16*1024*1024);
-        if ( codec == null )
-        {
+        if (codec == null) {
             log.info("reading split " + this.fileSplit.toString());
             fileIn.seek(fileSplit.getStart());
             in = fileIn;
-        }
-        else
-        {
-            if (fileSplit.getStart() > 0){
+        } else {
+            if (fileSplit.getStart() > 0) {
                 throw new IOException("File is not seekable but start of split is non-zero");
             }
             decompressor = CodecPool.getDecompressor(codec);
@@ -122,8 +119,8 @@ public class BSONFileRecordReader extends RecordReader<NullWritable, BSONObject>
     @Override
     public boolean nextKeyValue() throws IOException, InterruptedException {
         try{
-            if(filePosition.getPos() >= this.fileSplit.getStart() + this.fileSplit.getLength() &&
-            (codec == null || in.available()==0)){
+            if (filePosition.getPos() >= this.fileSplit.getStart() + this.fileSplit.getLength()
+                    && (codec == null || in.available() == 0)) {
                 try{
                     this.close();
                 }catch(Exception e){
diff --git a/core/src/main/java/com/mongodb/hadoop/mapred/input/BSONFileRecordReader.java b/core/src/main/java/com/mongodb/hadoop/mapred/input/BSONFileRecordReader.java
index e9fdddd..7dc1d90 100644
--- a/core/src/main/java/com/mongodb/hadoop/mapred/input/BSONFileRecordReader.java
+++ b/core/src/main/java/com/mongodb/hadoop/mapred/input/BSONFileRecordReader.java
@@ -76,15 +76,12 @@ public class BSONFileRecordReader implements RecordReader<NullWritable, BSONWrit
         codec = compressionCodecs.getCodec(file);
         FileSystem fs = file.getFileSystem(conf);
         FSDataInputStream fileIn = fs.open(file, 16*1024*1024);
-        if ( codec == null )
-        {
+        if (codec == null) {
             log.info("reading split " + this.fileSplit.toString());
             fileIn.seek(fileSplit.getStart());
             in = fileIn;
-        }
-        else
-        {
-            if (fileSplit.getStart() > 0){
+        } else {
+            if (fileSplit.getStart() > 0) {
                 throw new IOException("File is not seekable but start of split is non-zero");
             }
             decompressor = CodecPool.getDecompressor(codec);
@@ -107,8 +104,8 @@ public class BSONFileRecordReader implements RecordReader<NullWritable, BSONWrit
     @Override
     public boolean next(NullWritable key, BSONWritable value) throws IOException {
         try{
-            if(filePosition.getPos() >= this.fileSplit.getStart() + this.fileSplit.getLength() &&
-            (codec == null || in.available()==0)){
+            if (filePosition.getPos() >= this.fileSplit.getStart() + this.fileSplit.getLength()
+                    && (codec == null || in.available() == 0)) {
                 try{
                     this.close();
                 }catch(Exception e){
@@ -149,7 +146,7 @@ public class BSONFileRecordReader implements RecordReader<NullWritable, BSONWrit
     public long getPos() throws IOException {
         if(this.finished)
             return this.fileSplit.getStart() + this.fileSplit.getLength();
-        if(in != null )
+        if (in != null)
             return filePosition.getPos();
         return this.fileSplit.getStart();
     }
@@ -171,7 +168,7 @@ public class BSONFileRecordReader implements RecordReader<NullWritable, BSONWrit
         if(this.in != null){
             in.close();
         }
-        if (codec != null){
+        if (codec != null) {
             ((FSDataInputStream)this.filePosition).close();
         }
     }
diff --git a/core/src/main/java/com/mongodb/hadoop/splitter/BSONSplitter.java b/core/src/main/java/com/mongodb/hadoop/splitter/BSONSplitter.java
index a793bc1..c161336 100644
--- a/core/src/main/java/com/mongodb/hadoop/splitter/BSONSplitter.java
+++ b/core/src/main/java/com/mongodb/hadoop/splitter/BSONSplitter.java
@@ -26,7 +26,6 @@ import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-import java.lang.Long;
 import org.apache.commons.logging.*;
 import org.apache.hadoop.conf.*;
 import org.apache.hadoop.fs.BlockLocation;
@@ -156,18 +155,17 @@ public class BSONSplitter extends Configured implements Tool {
         FileSystem fs = path.getFileSystem(getConf());
         long length = file.getLen();
         boolean dosplits = true;
-        if(!getConf().getBoolean("bson.split.read_splits", true)){
+        if (!getConf().getBoolean("bson.split.read_splits", true)) {
             log.info("Reading splits is disabled - constructing single split for " + file);
             dosplits = false;
-        }
-        else{
+        } else {
             CompressionCodecFactory compressionCodecs = new CompressionCodecFactory(getConf());
-            if (compressionCodecs.getCodec(file.getPath()) != null){
+            if (compressionCodecs.getCodec(file.getPath()) != null) {
                 dosplits = false;
             }
             log.info("File is compressed - constructing single split for " + file);
         }
-        if(!dosplits){
+        if (!dosplits) {
             FileSplit onesplit = createFileSplit(file, fs, 0, length);
             splits.add(onesplit);
             this.splitsList = splits;
diff --git a/project/MongoHadoopBuild.scala b/project/MongoHadoopBuild.scala
index 7702a45..4fe8404 100644
--- a/project/MongoHadoopBuild.scala
+++ b/project/MongoHadoopBuild.scala
@@ -182,7 +182,7 @@ object MongoHadoopBuild extends Build {
       jar
     }
 
-  )
+   ) ++ Seq( publishMavenStyle := true) ++ Seq( publishTo := Some(Resolver.file("file", new File(Path.userHome.absolutePath+"/.m2/repository"))))
 
   val exampleSettings = dependentSettings ++ assemblySettings ++ Seq(
     mainClass in assembly := Some("com.mongodb.hadoop.examples.enron.EnronMail"),
